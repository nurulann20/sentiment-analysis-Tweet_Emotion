# -*- coding: utf-8 -*-
"""Analisis Sentimen Tweet Emotion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1McdK6BvoknL0ndgirx3t1AR2eEC1eUI-

# Import
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U textblob
# %python -m textblob.download_corpora
# %pip install keras==2.12.0
# %pip install tensorflow==2.12.0
# %pip install -U textblob
# %pip install wordcloud

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud, STOPWORDS
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report
from sklearn.naive_bayes import MultinomialNB
from imblearn.under_sampling import RandomUnderSampler
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
from google.colab import files
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
import re, string

file = files.upload()

data = pd.read_csv("tweet_emotions.csv")

"""# -- EDA"""

data.head()

data.info()

print("Total Data:")
print(data['sentiment'].value_counts())

import seaborn as sns
import matplotlib.pyplot as plt

# Hitung jumlah sentimen
sentiment_counts = data['sentiment'].value_counts()

# Gambar histogram
plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')
plt.title('Distribusi Jumlah Sentimen')
plt.xlabel('Sentimen')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Dari data atas, terlihat bahwa distribusi sentimen dalam dataset tidak seimbang. Mayoritas tweet terkumpul dalam kategori "neutral" dan "worry", sementara frekuensi tweet dalam kategori lainnya sangat bervariasi. Sentimen positif seperti "happiness" dan "love" memiliki frekuensi yang lebih rendah, sementara beberapa sentimen negatif seperti "anger" dan "boredom" bahkan memiliki frekuensi yang sangat minim. Ketidakseimbangan ini dapat memengaruhi performa model klasifikasi atau analisis sentimen, di mana kelas dengan frekuensi tinggi cenderung memiliki dampak lebih besar. Untuk memperbaiki ini, mungkin diperlukan penanganan khusus seperti oversampling atau undersampling untuk menyeimbangkan dataset, sehingga analisis lebih akurat dan representatif.

"""

def preprocess(ReviewText):
    ReviewText = ReviewText.str.replace("(<br/>)", "")
    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')
    ReviewText = ReviewText.str.replace('(&amp)', '')
    ReviewText = ReviewText.str.replace('(&gt)', '')
    ReviewText = ReviewText.str.replace('(&lt)', '')
    ReviewText = ReviewText.str.replace('(\xa0)', ' ')
    return ReviewText

data['content'] = preprocess(data['content'])

"""### Analisis Sentimen"""

data['Polarity'] = data['content'].apply(lambda x: TextBlob(x).sentiment.polarity)
data['word_count'] = data['content'].apply(lambda x: len(str(x).split()))
data['review_len'] = data['content'].apply(lambda x: len(str(x)))

"""Kode di atas digunakan  analisa sentimen dataset Twitter. Analisa sentimen (polarity) dapat membantu untuk mengetahui nilai polaritas sebuah data (apakah data memiliki konotasi positif/negatif), dengan rentang nilai -1 sampai 1. Word count digunakan untuk mengetahui distribusi jumlah kata yang terdapat pada setiap data dan review length mengetahui distribusi jumlah karakter yang terdapat pada setiap data yang terdapat pada fitur text.

"""

cl = data.loc[data.Polarity <= 0.5, ['content']].sample(5).values
for c in cl:
    print(c[0])

"""Di atas merupakan contoh 5 data yang memiliki nilai polarity lebih dari 0,5"""

cl = data.loc[data.Polarity == 0, ['content']].sample(5).values
for c in cl:
    print(c[0])

"""Di atas merupakan contoh 5 data yang memiliki nilai polarity 0"""

cl = data.loc[data.Polarity <= -0.5, ['content']].sample(5).values
for c in cl:
    print(c[0])

"""Di atas merupakan contoh 5 data yang memiliki nilai polarity kurang dari -0,5"""

features = ['Polarity', 'review_len', 'word_count']
titles = ['Polarity Distribution', 'Review length Distribution', 'Word Count Distribution']
colors = ['#9966ff', '#3399ff', '#00ff00', '#ff6600']


for feature, title, color in zip(features, titles, colors):
    sns.histplot(data[feature], bins=50, color=color, kde=True)
    sns.kdeplot(data[feature], color=color, linestyle='--')
    plt.title(title, size=15)
    plt.xlabel(feature)
    plt.ylabel("Density")
    plt.show()

"""Di atas merupakan grafik distribusi Polarity, Review_len dan Word Count
1. Polarity Distribution

  Dari data atas, terlihat bahwa distribusi sentimen dalam dataset tidak seimbang. Mayoritas tweet terkumpul dalam kategori "neutral" dan "worry", sementara frekuensi tweet dalam kategori lainnya sangat bervariasi. Sentimen positif seperti "happiness" dan "love" memiliki frekuensi yang lebih rendah, sementara beberapa sentimen negatif seperti "anger" dan "boredom" bahkan memiliki frekuensi yang sangat minim. Ketidakseimbangan ini dapat memengaruhi performa model klasifikasi atau analisis sentimen, di mana kelas dengan frekuensi tinggi cenderung memiliki dampak lebih besar. Untuk memperbaiki ini, mungkin diperlukan penanganan khusus seperti oversampling atau undersampling untuk menyeimbangkan dataset, sehingga analisis lebih akurat dan representatif.

2. Review Length Distribution

  Dari hasil analisis polaritas, mayoritas nilai terkonsentrasi di sekitar 0, yang menunjukkan bahwa mayoritas data memiliki polaritas netral. Rentang nilai polaritas dari -1 hingga 1 menunjukkan sejauh mana sentimen dalam data cenderung positif atau negatif, di mana nilai positif menunjukkan sentimen positif dan nilai negatif menunjukkan sentimen negatif. Dengan mayoritas nilai polaritas mendekati 0, hal ini menunjukkan bahwa data cenderung netral secara emosional, dengan sedikit kecenderungan positif atau negatif. Hal ini bisa mengindikasikan bahwa dalam kumpulan data tersebut, tweet-tweet yang dianalisis memiliki tingkat kesetimbangan antara sentimen positif dan negatif.

3. Word Count Distribution

  Dari grafik distribusi jumlah kata dalam tweet, terlihat bahwa sebagian besar tweet memiliki jumlah kata berkisar antara 0 hingga sekitar 35 kata. Nilai terbanyak terkonsentrasi di sekitar 5 hingga 10 kata, menunjukkan bahwa mayoritas tweet memiliki panjang yang relatif singkat.

## Word Cloud
"""

comment_words = ''
stopwords = set(STOPWORDS)

for val in data.content:

	val = str(val)

	tokens = val.split()

	for i in range(len(tokens)):
		tokens[i] = tokens[i].lower()

	comment_words += " ".join(tokens)+" "

wordcloud = WordCloud(width = 800, height = 800,
				background_color ='white',
				stopwords = stopwords,
				min_font_size = 10).generate(comment_words)

plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)

plt.show()

"""Dari wordcloud yang dihasilkan setelah menghilangkan stop word, kata-kata yang sering muncul, ditandai dengan ukuran yang besar, adalah "work", "quote", "love", dan "now". Ini menunjukkan bahwa dalam dataset tersebut, kata-kata tersebut memiliki frekuensi kemunculan yang tinggi dan mungkin menjadi fokus utama dalam tweet-tweet yang dianalisis.

# -- Data Preparation dan Preprocessing
"""

# CUSTOM DEFINED FUNCTIONS TO CLEAN THE DATA

# Remove punctuations, links, mentions and \r\n new line characters
def strip_all_entities(text):
    text = text.replace('\r', '').replace('\n', ' ').replace('\n', ' ').lower() #remove \n and \r and lowercase
    text = re.sub(r"(?:\@|https?\://)\S+", "", text) #remove links and mentions
    text = re.sub(r'[^\x00-\x7f]',r'', text) #remove non utf8/ascii characters such as '\x9a\x91\x97\x9a\x97'
    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'
    table = str.maketrans('', '', banned_list)
    text = text.translate(table)
    return text

# Clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol
def clean_hashtags(tweet):
    new_tweet = " ".join(word.strip() for word in re.split('#(?!(?:hashtag)\b)[\w-]+(?=(?:\s+#[\w-]+)*\s*$)', tweet)) #remove last hashtags
    new_tweet2 = " ".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence
    return new_tweet2

# Filter special characters such as & and $ present in some words
def filter_chars(a):
    sent = []
    for word in a.split(' '):
        if ('$' in word) | ('&' in word):
            sent.append('')
        else:
            sent.append(word)
    return ' '.join(sent)

# Remove multiple spaces
def remove_mult_spaces(text):
    return re.sub("\s\s+" , " ", text)

# Drop duplicate
twitter.drop_duplicates(inplace = True)
twitter.reset_index(drop = True, inplace=True)
print("Sum of Duplicated Data in Twitter No Adver ",twitter.duplicated().sum())

# Lower Case All dataframe
twitter['content'] = twitter['content'].apply(lambda x: x.lower())

# Remove multi space
texts_new_twitter = []
for t in twitter['content']:
    texts_new_twitter.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(t)))))

twitter['content'] = texts_new_twitter

# Membersihkan nilai NaN
twitter.dropna(how='any', inplace=True)

# Menghitung jumlah nilai NaN dalam kolom 'content'
jumlah_nan = twitter['content'].isnull().sum()
print("Jumlah nilai NaN dalam kolom 'content':", jumlah_nan)

twitter

# Simpan DataFrame ke file CSV
twitter.to_csv('tweet_emotions_preprocessed.csv', index=False)

"""# -- Training & Testing"""

# Naive Bayes
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, recall_score, precision_score

# SVM
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

file = files.upload()

data = pd.read_csv("tweet_emotions_preprocessed.csv")

"""## Naive Bayes"""

# Pilih kolom yang akan digunakan sebagai fitur dan label
X = data['content']
y = data['sentiment']

# Bagi data menjadi set pelatihan dan pengujian
X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Ekstraksi fitur menggunakan TfidfVectorizer
vectorizer_nb = TfidfVectorizer(max_features=1000)
X_train_vec_nb = vectorizer_nb.fit_transform(X_train_nb)
X_test_vec_nb = vectorizer_nb.transform(X_test_nb)

# Model Naive Bayes
nb_model = MultinomialNB()

# Pelatihan model
nb_model.fit(X_train_vec_nb, y_train_nb)

# Prediksi pada data uji
y_pred_nb = nb_model.predict(X_test_vec_nb)

# Akurasi pada data latih dan uji
train_accuracy_nb = accuracy_score(y_train_nb, nb_model.predict(X_train_vec_nb))
test_accuracy_nb = accuracy_score(y_test_nb, y_pred_nb)
print("Akurasi pada data latih:", train_accuracy_nb)
print("Akurasi pada data uji:", test_accuracy_nb)

# Stratified k-Fold Cross-Validation
skf = StratifiedKFold(n_splits=5)

# Ekstraksi fitur pada seluruh data
X_vec = vectorizer_nb.fit_transform(X)

# Evaluasi model menggunakan stratified k-fold cross-validation
scores = cross_val_score(nb_model, X_vec, y, cv=skf, scoring='accuracy')

# Cetak hasil akurasi untuk setiap fold dan rata-ratanya
print("Akurasi untuk setiap fold:", scores)
print("Akurasi rata-rata:", scores.mean())

# Pilih kolom yang akan digunakan sebagai fitur dan label
X = data['content']
y = data['sentiment']

# Melakukan Konversi text data menjadi format numerical menggunakan CountVectorizer
vectorizer_nb = CountVectorizer(max_features=10000)
X_vectorized_nb = vectorizer_nb.fit_transform(X)

# 3. Ekstraksi fitur
vectorizer_svm = TfidfVectorizer(max_features=1000)
X_train_vec_svm = vectorizer_svm.fit_transform(X_train)
X_test_vec_svm = vectorizer_svm.transform(X_test)

# Bagi data menjadi set pelatihan dan pengujian
X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Ekstraksi fitur
vectorizer_nb = TfidfVectorizer(max_features=1000)
X_train_vec_nb = vectorizer_nb.fit_transform(X_train_nb)
X_test_vec_nb = vectorizer_nb.transform(X_test_nb)

# Model Naive Bayes
nb_model = MultinomialNB()

# Pelatihan model
nb_model.fit(X_train_vec_nb, y_train_nb)

# Prediksi pada data uji
y_pred_nb = nb_model.predict(X_test_vec_nb)

# Akurasi pada data latih dan uji
train_accuracy_nb = accuracy_score(y_train_nb, nb_model.predict(X_train_vec_nb))
test_accuracy_nb = accuracy_score(y_test_nb, y_pred_nb)
print("Akurasi pada data latih:", train_accuracy_nb)
print("Akurasi pada data uji:", test_accuracy_nb)

# Confusion Matrix
cm_nb = confusion_matrix(y_test_nb, y_pred_nb)
sns.heatmap(cm_nb, annot=True, fmt="d", cmap="Blues", xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Precision, Recall, F1-score
classification_rep_nb = classification_report(y_test_nb, y_pred_nb, target_names=nb_model.classes_)
print("Classification Report:")
print(classification_rep_nb)

# Perhitungan Matriks Evaluasi
print("Overall testing Naive Bayes:")
accuracy_nb = accuracy_score(y_test_nb, y_pred_nb)
f1_nb = f1_score(y_test_nb, y_pred_nb, average='weighted')
recall_nb = recall_score(y_test_nb, y_pred_nb, average='weighted')
precision_nb = precision_score(y_test_nb, y_pred_nb, average='weighted')

print("Accuracy: {:.2%}".format(accuracy_nb))
print("F1 Score: {:.2f}".format(f1_nb))
print("Recall: {:.2f}".format(recall_nb))
print("Precision: {:.2f}".format(precision_nb))

"""## SVM"""

# 1. Pilih kolom yang akan digunakan sebagai fitur dan label
X = data['content']
y = data['sentiment']

# 2. Pembagian data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Ekstraksi fitur
vectorizer_svm = TfidfVectorizer(max_features=1000)
X_train_vec_svm = vectorizer_svm.fit_transform(X_train)
X_test_vec_svm = vectorizer_svm.transform(X_test)

# 4. Hyperparameter tuning dengan GridSearchCV
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}

grid_search_svm = GridSearchCV(SVC(), param_grid, cv=5, verbose=2, n_jobs=-1)
grid_search_svm.fit(X_train_vec_svm, y_train)

# 5. Pelatihan model dengan parameter terbaik
best_svm_model = grid_search_svm.best_estimator_
best_svm_model.fit(X_train_vec_svm, y_train)

# 6. Evaluasi model
# Mendapatkan parameter terbaik
best_params_svm = grid_search_svm.best_params_
print("Parameter terbaik:", best_params_svm)

# Akurasi pada data latih
y_train_pred_svm = best_svm_model.predict(X_train_vec_svm)
train_accuracy_svm = accuracy_score(y_train, y_train_pred_svm)
print("Akurasi pada data latih:", train_accuracy_svm)

# Akurasi pada data uji
y_test_pred_svm = best_svm_model.predict(X_test_vec_svm)
test_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)
print("Akurasi pada data uji:", test_accuracy_svm)

# Confusion Matrix
cm_svm = confusion_matrix(y_test, y_test_pred_svm)
plt.figure(figsize=(10, 7))
sns.heatmap(cm_svm, annot=True, fmt="d", cmap="Blues", xticklabels=best_svm_model.classes_, yticklabels=best_svm_model.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
classification_rep_svm = classification_report(y_test, y_test_pred_svm, target_names=best_svm_model.classes_)
print("Classification Report:")
print(classification_rep_svm)

# Perhitungan Matriks Evaluasi
f1_svm = f1_score(y_test, y_test_pred_svm, average='weighted')
recall_svm = recall_score(y_test, y_test_pred_svm, average='weighted')
precision_svm = precision_score(y_test, y_test_pred_svm, average='weighted')

print("Accuracy: {:.2f}%".format(test_accuracy_svm * 100))
print("F1 Score: {:.2f}".format(f1_svm))
print("Recall: {:.2f}".format(recall_svm))
print("Precision: {:.2f}".format(precision_svm))